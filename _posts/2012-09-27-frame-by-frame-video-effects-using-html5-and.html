---
layout: post
title: Frame by frame video effects using HTML5 canvas and video
categories:
- Web Development
tags:
- Canvas
- HTML5
- Javascript
- Video
status: publish
type: post
published: true
---
<p>As it has been illustrated with talent in a <a href="http://www.craftymind.com/2010/04/20/blowing-up-html5-video-and-mapping-it-into-3d-space/">famous craftymind article</a>, the HTML5 video element can be used as a source input to draw frames into a canvas element to perform live video post-processing.<!--more--></p>
<p>This post gives another demonstration of what can be achieved using this powerful technique, by applying live image filters and effects on a running video.</p>
<h2>Design principles</h2>
<p>The frames rendered by a video element are captured at regular intervals by a canvas element used as a framebuffer, and the resulting images are post-processed through javascript before being displayed on-screen inside another canvas used as a viewport.</p>
<p>I use the <a href='http://joelb.me/jsmanipulate/'>JSManipulate</a> library by Joel Besada for frames post-processing.</p>
<p>It is an image filter and effects library written in Javascript for client-side manipulation of images on a web page.</p>
<h2>Implementation details</h2>
<p>The code for this demonstration looks like this:</p>
<pre class="prettyprint">
function frameConverter(video,canvas) {

    // Set up our frame converter
    this.video = video;
    this.viewport = canvas.getContext(&quot;2d&quot;);
    this.width = canvas.width;
    this.height = canvas.height;
    // Create the frame-buffer canvas
    this.framebuffer = document.createElement(&quot;canvas&quot;);
    this.framebuffer.width = this.width;
    this.framebuffer.height = this.height;
    this.ctx = this.framebuffer.getContext(&quot;2d&quot;);
    // Default video effect is blur
    this.effect = JSManipulate.blur;
    // This variable used to pass ourself to event call-backs
    var self = this;
    // Start rendering when the video is playing
    this.video.addEventListener(&quot;play&quot;, function() {
        self.render();
      }, false);
      
    // Change the image effect to be applied  
    this.setEffect = function(effect){
      if(effect in JSManipulate){
          this.effect = JSManipulate[effect];
      }
    }

    // Rendering call-back
    this.render = function() {
        if (this.video.paused || this.video.ended) {
          return;
        }
        this.renderFrame();
        var self = this;
        // Render every 10 ms
        setTimeout(function () {
            self.render();
          }, 10);
    };

    // Compute and display the next frame 
    this.renderFrame = function() {
        // Acquire a video frame from the video element
        this.ctx.drawImage(this.video, 0, 0, this.video.videoWidth,
                    this.video.videoHeight,0,0,this.width, this.height);
        var data = this.ctx.getImageData(0, 0, this.width, this.height);
        // Apply image effect
        this.effect.filter(data,this.effect.defaultValues);
        // Render to viewport
        this.viewport.putImageData(data, 0, 0);
    return;
    };
};

// Initialization code
video = document.getElementById(&quot;video&quot;);
canvas = document.getElementById(&quot;canvas&quot;);
fc = new frameConverter(video,canvas);
...
// Change the image effect applied to the video
fc.setEffect(&#039;edge detection&#039;);

</pre>
<p>As you can see, the prerequisites are to either reference or allocate a <code>video</code> element to be used as a source for video frames, and a <code>canvas</code> element to be used a viewport to display transformed frames.</p>
<p>The frame by frame conversion is performed here by a dedicated javascript object (<code>frameConverter</code>) that takes this source and viewport as parameters.</p>
<p>The <code>frameConverter</code> object dynamically allocates a new <code>canvas</code> element to be used as a frameBuffer (Please note that this element doesn't need to be inserted in the DOM).</p>
<p>As soon as the <code>frameConverter</code> detects that the video is playing in the <code>video</code> element, it starts the rendering loop that will perform the following tasks every 10 ms:
<ul>
<li>transfer the current video frame from the <code>video</code> element to the framebuffer <code>canvas</code>,</li>
<li>grab the frame data from the framebuffer,</li>
<li>apply the selected image effect to the frame data,</li>
<li>put the transformed frame to the viewport <code>canvas</code>.</li>
</ul> 
<p>
Check out the <a href="/demos/video-effects-demo/">Live Demo</a>.
</p>
